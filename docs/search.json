[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Cox Proportion Models\nDimir, Ivan\nIntroduction\nMethods\nResults\nReferences"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "",
    "section": "",
    "text": "Introduction\nThe Application of the Cox Proportional Hazard Model and Its Application and Effectiveness\nThe Cox Proportional Hazard Model, also known as the Cox Regression or Cox PH model is an important statistical tool used in survival analysis. This model was developed in 1972 by a British statistician by the name of Sir David R. Cox to analyze time-to-event data. Survival analysis such as the Cox Regression is a time-to-event analysis, used to investigate the time until the occurrence of an event of interest. Applications of this regression model go far beyond statistical setting and are widely used in medical research and are growing in use in reliability engineering and other outcomes research. In this introduction, we will review Cox Regression, delve deeper into how the Cox Regression has been applied to three different medical research papers, note some of its uses outside of the medical field, and discuss how effective statistical analysis is.\nPrior to the publication of the Cox Proportional Hazard model, tests such as the log-rank test were used but limited to observing the effect of one variable at a time [1]. Additionally, the logrank test could not quantify the effect of the variables [1]. The Cox proportional hazards model estimates the hazard as [1]:\n\\(h(t)=h_n(t) \\exp \\left(B_1 X_1+B_2 X_2+\\ldots B_p X_p\\right)\\)\n\\(h\\) is the hazard at time \\(t\\), \\(h_u(t)\\) is the baseline hazard, \\(\\mathrm{X}\\) are the covariates.\nThe Cox proportional hazard model assumes the hazard rate is a product of a baseline hazard rate, that that baseline hazard rate is the hazard rate when the covariates have no effect on the event. A regression vector is estimated by maximizing a marginal, partial, or maximum likelihood function. The significance of the covariates can be tested with analytical methods (log rank test, or chi-squared test) or graphical methods (cumulative hazard rate plots or residual plots). Insignificant covariates can be removed and a regression vector recalculated [2].\nModel Assumptions\nDividing both sides by \\(h_0(t)\\) yields the hazard ratio\n\\(\\mathrm{h}(\\mathrm{t}) / \\mathrm{h}_{\\mathrm{o}}(\\mathrm{t})=\\exp \\left(\\mathrm{B}_1 \\mathrm{X}_1+\\mathrm{B}_2 \\mathrm{X}_2+\\ldots \\mathrm{B}_{\\mathrm{p}} \\mathrm{X}_{\\mathrm{p}}\\right) \\text {. }\\)\nThis hazard ratio must remain constant over time to fit the assumptions of the Cox \\(\\mathrm{PH}\\) model. Babinska, et al. emphasize this in their paper looking at the Cox PH model’s use in analyzing the outcomes of patients with acute coronary syndrome [3]. Cox proportional hazard model also assumes events are independent and that censoring is uninformative [1]. That is that the time to event for one person (or thing) is independent of the time to event for another person (or thing) and people (or things) who do not continue to the end of the study, aka. are censored, have the same risk of the event as those that do continue until the end of the study period.\nReasons the Cox proportional hazards model is popular is that it does not require the baseline hazard, \\(h_0(t)\\) to be known [1].\nBabinska, et al. look into the limitations of Cox Regression in predicting mortality rates in patients with acute coronary syndrome (ACS) [3]. Although there have been significant advances in medicine and interventional therapies, cardiovascular disease (CVD) still burdens the medical system. The researchers see the importance of Cox Regression but worry about a potential violation of the proportionality of hazard assumption using a simple Cox regression model [3]. The study at first examined if proportional hazard assumptions are met in various factors including homocysteine and sodium concentrations. These assumptions are important for accurate Cox regression analysis because they ensure that hazard ratios remain constant. The study found there was a violation in some of the cases, such as homocysteine and sodium concentrations. Without verification of these assumptions, the increased risk of death due to ACS might be incorrectly identified. The study looked into one hundred and fifty consecutive patients with acute coronary syndrome (ACS) with a mean age of 65 (range; 21-92 years), 33 (22%) deaths was registered during the follow-up period of 64 months [3]. In the Cox regression model, several factors were identified as risk factors for long-term prognosis in patients with ACS. The factors included smoking, the presence of diabetes and anemia, the duration of coronary artery disease, and abnormal serum concentrations of uric acid, sodium, homocysteine, cystatine C, and NT-proBNP. The study stressed the importance of ensuring that the proportional hazard assumption is met in the Cox regression. Failure to meet the assumption can lead to false positives in the conclusion and incorrect identification of factors leading to ACS-related deaths. To remedy the violation, the study recommends using the Cox stratified regression model or extended regression models with time-dependent variables. The next study investigated the impact of regional medical disparities on complications in patients with hypertension while using the Cox Proportional Hazard model. The study took place in South Korea since it has become the fastest-aging country worldwide, and there is a greater likelihood of an increase in the prevalence of hypertension [4]. As of 2022, Seoul, the capital of South Korea, had 4.8 doctors per 1,000 inhabitants, and except for metropolitan cities (Busan, Daegu), all the other areas had an average of less than 3.2 doctors per 1,000 inhabitants [5]. The disparities between the number of physicians in the more populated regions and the rural areas play an important role in hypertension compilations. The study’s results aligned with similar studies conducted in China, Romania, and the United States. These studies also reported a correlation between disparities in hypertension treatment and control, particularly in rural areas. The study also suggested that the higher risk of hypertension complications in medically vulnerable regions may be due to disparities in access to healthcare. The study included a cohort of 246,490 participants, with the goal of investigating the interaction between residential regions (vulnerable vs. non-vulnerable) and diagnosis areas (outside vs. inside) in relation to complications in patients. The participants were divided into four groups — vulnerable and outside region, vulnerable and inside region, non-vulnerable and outside region, and non- vulnerable and inside region. Multivariate Cox regression analysis was fitted. The interaction term between the residential region (vulnerable vs. non-vulnerable) and the diagnosis area (outside vs. inside) was significant in the adjusted model (p-value =0.005) [4]. The Cox regression showed that individuals living in vulnerable and outside regions had the highest risk of complications. This analysis was supported by the hazard ratio (HR) in which vulnerable and outside regions had the highest ratio of 1.l56. The vulnerable and outside region group had the highest rate of complications for cardiovascular and cerebrovascular diseases when compared to\nthe reference group. However, for kidney disease, the non-vulnerable and outside region group had the highest rate of complications. In this third article, researchers are using Cox regression in addition to Artificial Neural Network (ANN) to postoperative mortality after hip fracture surgery. Postoperative mortality is any death, regardless of cause thirty-days after surgery. As the population is aging more hip fracture has become a public health issue [6]. The substantial associated medical costs in the United Kingdom (UK) and Taiwan have increased for these procedures. This is why understanding and predicting the underlying causes of postoperative mortality after hip surgeries is of great importance. Traditional parameter models have not been reliable enough, ANN and Cox regression models are used due to the fact they are the most common models used in the healthcare industry for predicting postoperative mortality. The ANN model captures nonlinear interactions among risk factors, making it favorable in medical decision-making and mortality predictions. Cox proportional hazard (PH) model is standard in survival analysis but has a limitation in predicting longitudinal survival. The purpose of the study is to use ANN and Cox models to identify influential predictors of postoperative mortality after hip fracture and conduct a global sensitivity analysis to assess important predictors. In total, researchers analyzed 10,534 hip fracture procedures. During this period, 71.2% hip fracture patients were referred to lower- level medical institutions for rehabilitation after surgery, and 28.8% patients continued treatment at the same medical institution [7]. The mean age of patients was 68.3 (SD 14.6) years, with females representing 57.6% of the patients [7]. The training data set was 7374 cases, the testing data set of 1580 cases and the same number of 1580 for the validation dataset. The study found that the artificial neural networks (ANN) model outperformed the Cox regression model in predicting postoperative mortality after hip fracture surgery. Comparisons of performance indices in the testing dataset also showed that the ANN model significantly outperformed the Cox model in sensitivity (0.96 vs. 0.92, p < 0.001), specificity (0.76 vs. 0.64, p < 0.001), PPV (0.88 vs. 0.78, p < 0.001), NPV (0.84 vs. 0.77, p < 0.001), accuracy (0.93 vs. 0.90, p < 0.001), and AUROC (0.93 vs. 0.88, p < 0.001) [6]. In addition, what makes this study unique is the fact they are the first to utilize a nationwide population-based dataset for both training and testing an ANN to forecast outcomes of hip fracture surgery. As often, in previous studies data often originates from a single medical center. While the Cox PH model is widely used in medicine, it is also used in other fields as well. Previously reliability engineering used homogeneous Poisson processes and renew process [2]. However, these only look at the variable of time-to-the-event, ignoring all other variables. In the real world, hazard rate of the failure of an item is influenced by the conditions under which it operates, these conditions, or covariates, are what the Cox proportional hazard model takes into account. Proportional hazard models have been used to model component failure in nuclear plant, ship sonar, aircraft engines, train breaks, safety valves, aircraft doors, power cables, among other areas [2]. This paper also recounts situations that may require covariates that depend on time: wear on a device, growth of a crack [2]. If a time dependent covariate is introduced the model becomes a nonproportional hazards model and there are additional methods beyond the basic Cox PH model for handling this.\nIn summary, the first study stresses the importance of meeting the proportional hazard assumption in Cox regression analysis, particularly in the context of ACS patients. The importance of not violating the assumption and the need for appropriate modeling techniques to address violations for accurate and reliable prognosis needs to be of the utmost importance when using Cox regression analysis. The second article shed light on regional medical disparities in hypertension complications. The third article highlights the effectiveness of combining the Cox regression model with Artificial neural network (ANN). As the Cox regression model was outperformed by the ANN model when predicting postoperative mortality after hip fracture surgery. It brings to light the importance of equitable healthcare access and the introduction of policies aimed at reducing regional healthcare disparities for better management of patients with hypertension. Lastly the fourth paper reviewed here expands the usefulness of the Cox regression model beyond the medical field to the filed of systems failure and reliability engineering."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "",
    "section": "",
    "text": "Summary\nIn summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "",
    "section": "",
    "text": "library(survival)\n#install.packages(\"survminer\")\nlibrary(survminer)\n\nLoading required package: ggplot2\n\n\nLoading required package: ggpubr\n\n\n\nAttaching package: 'survminer'\n\n\nThe following object is masked from 'package:survival':\n\n    myeloma\n\n\n\n\nThe Cox Proportional Hazard Model (PHM) is best suited for this data due to the fact that this model is used to examine a time-to-event outcome, t, as a function of more than one predictor variable xi . What makes Cox PHM unique compared to other models is the fact that it adjusts for censoring. Censoring occurs when the exact time of exposure before an event is unknown. The three main reasons for censoring are: (1) a person does not experience the event before the end of the experiment; (2) a person does not check-in during study; or (3) a person withdraws from the experiment for reasons other than the event of interest (e.g. death in most survival analysis) [1]. A strength of the Cox PHM allows the inclusion of patients who have not had the event. Information is still provided by the patient up to the time of censoring, which informs the overall time to events in the population.\nThe Cox regression model is based on the hazard function. Mathematically written as :\n\\[\nh_i(t)=h_0(t) \\times e\\beta_0 + \\beta_1X_{i1} + \\beta_{2}X_{i2} + \\dots + \\beta n X_{in}\n\\]\nWhere i= 1,2,…, N indexes patients, t represents time, \\(h_i(t)\\) is the hazard function for person i at time period t, h_0 is the baseline hazard, X_{i1} ,X_{i2} , … X_{in} is a set of independent variables (predictor variables) for person i and \\(𝛽_0\\) are the regression coefficients for the independent variables [2].\nLinear regression model on the other hand is not a good fit for this type of data for the following reasons. Survival analysis has two unique characteristics that linear regression doesn’t handle well, censoring and time to event outcomes. Censored data is assumed to be all completed under linear regression and that is not the case in survival analysis. Secondly, linear regression assumes a constant relationship between predictors and response variables. Survival data can exhibit hazard rates, which linear regression can not handle too well.\nThe other survival analysis model that is often used is the Kaplan-Meier (KM) Survival Analysis. K-M survival analysis is best used to measure the fraction of subjects living for a certain amount of time after treatment [3]. Censored observations don’t hinder the K-M analysis similarly to Cox PMH. The one thing that Cox PMH can do that K-M analysis cannot is performing multivariate analysis by assessing the simultaneous effects of multiple predictor variables on survival outcomes (such as what we are doing with our data), because of this K-M analysis is considered univariate analysis [4].\nData for our cox regression analysis comes from the Stanford University Heart Transplant Study. The study was conducted to determine if an experimental heart transplant program may increase the lifespan of the recipient. Each patient in the program is considered an official heart transplant candidate, meaning they have an illness that will most likely need a heart transplant in order to prolong their lives. Patients heart transplant occurs between a few weeks to several months which all depends on donor heart availability. Although few candidates during the waiting period show improvement and get deselected as heart transplant candidates, they are kept in the data as continuing candidates [5]. These continuing candidates contribute to the censoring data.\nThe variables included in the Cox model as the x variable (or predictors) are accepted year, age, prior and transplant. Accepted year was the year the patient was included as an official candidate in the experiment and in the data these values are stored under “acceptyear”. Their age when accepted in the study is labeled “age”. Third predictor is whether or not the patient had prior surgeries with the header “prior”. Finally, transplant status, if the patient received the heart transplant or not stored under the column name “transplant”. The criteria (y variable) are survival status weather they survived until the end of the experiment, and the number of days a patient lived for after receiving the transplant is labeled “survtime”.\nVariables within the data set such as, the columns: survived, prior, and transplant needed to be converted from characteristic columns to numeric columns. A model was generated without the variable wait time due to the fact that only patients who received the transplant had a wait time. In order to include more patients (n=103) into the model, wait time was not chosen as a predictor variable.\nThe data was categorized into under 40, 40-50, and 50 and over, a histogram was generated \\(\\textbf Image 2\\) shows from one age category to another a patient is twice as likely to die. This does not include accounting for if you get a transplant or not. Being in need of a transplant, in addition to going from one age group to another the risk of dying is doubled. Two Cox proportional hazard models (PHM) are used in order to stratify the data on the transplant variable. One Cox PHM for those who receive the transplant and one for those who do not. When the data is stratified by transplant status, non-proportionality is better visualized as seen in \\(\\textbf Image 1\\), those that do not have the transplant die off at a much steeper rate than those that do have transplant. Image 1 Survival rate with Transplant and without Transplant Image 2 Risk of dying due to age group.\n\\(\\textbf Image 1\\) Survival rate with Transplant and without Transplant\n\nheart_transplant <- read.csv(\"./heart_transplant.csv\")\n#generate numeric columns for survived, prior, and transplant from existing charachter columns\nheart_transplant$survived2 <- as.numeric(ifelse(heart_transplant$survived==\"dead\",1,0))\nheart_transplant$prior2 <- as.numeric(ifelse(heart_transplant$prior==\"yes\",1,0))\nheart_transplant$transplant2 <- as.numeric(ifelse(heart_transplant$transplant==\"treatment\",1,0))\nall_strTrtmnt.mod <- coxph(Surv(survtime, survived2)~ age + prior2 + strata(transplant2), data=heart_transplant)\nsummary(all_strTrtmnt.mod)\n\nCall:\ncoxph(formula = Surv(survtime, survived2) ~ age + prior2 + strata(transplant2), \n    data = heart_transplant)\n\n  n= 99, number of events= 71 \n\n           coef exp(coef) se(coef)      z Pr(>|z|)   \nage     0.04662   1.04773  0.01434  3.250  0.00115 **\nprior2 -0.78988   0.45390  0.44480 -1.776  0.07576 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\nage       1.0477     0.9544    1.0187     1.078\nprior2    0.4539     2.2031    0.1898     1.085\n\nConcordance= 0.642  (se = 0.038 )\nLikelihood ratio test= 15.95  on 2 df,   p=3e-04\nWald test            = 13.96  on 2 df,   p=9e-04\nScore (logrank) test = 14.36  on 2 df,   p=8e-04\n\n\n\nggsurvplot(survfit(all_strTrtmnt.mod), data=heart_transplant, ggtheme = theme_minimal(), conf.int=TRUE, risk.table=TRUE, tables.height = 0.3, tables.theme = theme_minimal())\n\n\n\n\n\nheart_transplant$age2 <- as.numeric(ifelse(heart_transplant$age<41,0,ifelse(heart_transplant$age<51,1,2)))\nhist(heart_transplant$age2, xlab=\"Age (<40, 40-49, 50+)\")\n\n\n\n#generate model with chategorized age\nall_agechat.mod <- coxph(Surv(survtime, survived2)~ age2 + prior2 + strata(transplant2), data=heart_transplant)\nsummary(all_agechat.mod)\n\nCall:\ncoxph(formula = Surv(survtime, survived2) ~ age2 + prior2 + strata(transplant2), \n    data = heart_transplant)\n\n  n= 99, number of events= 71 \n\n          coef exp(coef) se(coef)      z Pr(>|z|)    \nage2    0.7337    2.0828   0.1808  4.059 4.93e-05 ***\nprior2 -0.7177    0.4879   0.4451 -1.613    0.107    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n       exp(coef) exp(-coef) lower .95 upper .95\nage2      2.0828     0.4801    1.4614     2.968\nprior2    0.4879     2.0497    0.2039     1.167\n\nConcordance= 0.634  (se = 0.041 )\nLikelihood ratio test= 20.9  on 2 df,   p=3e-05\nWald test            = 20.01  on 2 df,   p=5e-05\nScore (logrank) test = 21.14  on 2 df,   p=3e-05\n\n\n[1] A. N. Kulaylat and L. Tran, “Chapter 26- Regression Analysis ,” in Translational surgery, Amsterdam : ELSEVIER ACADEMIC PRESS, 2023, pp. 157–163\n[2] S. Abd ElHafeez et al., “Methods to analyze time-to-event data: The Cox Regression Analysis,” Oxidative medicine and cellular longevity, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8651375/ (accessed Oct. 20, 2023).\n[3] M. K. Goel, P. Khanna, and J. Kishore, “Understanding survival analysis: Kaplan-Meier estimate,” International journal of Ayurveda research, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3059453/#:~:text=may%20become%20small.-, The%20Kaplan%2DMeier%20estimate%20is%20the%20simplest%20way%20of%20computing ,associated%20with%20subjects%20or%20situations.&text=For%20each%20time%20interval% 2C%20survival,number%20of%20patients%20at%20risk. (accessed Oct. 20, 2023).\n[4] W. N. Dudley, R. Wickham, and N. Coombs, “An introduction to survival statistics: Kaplan-Meier analysis,” Journal of the advanced practitioner in oncology, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5045282/ (accessed Oct. 20, 2023).\n[5] Turnbull B, Brown B, and Hu M (1974). “Survivorship of heart transplant data.” Journal of the American Statistical Association, vol. 69, pp. 74-80."
  },
  {
    "objectID": "Results.html",
    "href": "Results.html",
    "title": "",
    "section": "",
    "text": "library(survival)\n#install.packages(\"survminer\")\nlibrary(survminer)\n\nLoading required package: ggplot2\n\n\nLoading required package: ggpubr\n\n\n\nAttaching package: 'survminer'\n\n\nThe following object is masked from 'package:survival':\n\n    myeloma"
  },
  {
    "objectID": "Results.html#code",
    "href": "Results.html#code",
    "title": "",
    "section": "Code",
    "text": "Code\n\ntreated.mod <- coxph(Surv(survtime, survived2)~ acceptyear + age + prior + wait, data=heart_transplant)\n\nThird model without an accepted year was generated and then compared using an ANOVA table (see Table 4). The p-value = 0.1656 which is greater than 0.05 and we can drop the accepted year as a variable."
  },
  {
    "objectID": "Results.html#code-1",
    "href": "Results.html#code-1",
    "title": "",
    "section": "Code",
    "text": "Code\n\n#generate model without accepted year\nall2.mod <- coxph(Surv(survtime, survived2)~ age + prior + transplant, data=heart_transplant)\n\nThe C-statistic for the model without an accepted year is equal to 0.739 (see Table 3). Which shows that this model has a higher predictability capabilities compared to the model including the accepted year with a C-statistic = 0.683."
  },
  {
    "objectID": "Results.html#code-2",
    "href": "Results.html#code-2",
    "title": "",
    "section": "Code",
    "text": "Code\n\n#examine model\nsummary(all2.mod)\n\nCall:\ncoxph(formula = Surv(survtime, survived2) ~ age + prior + transplant, \n    data = heart_transplant)\n\n  n= 99, number of events= 71 \n\n                        coef exp(coef) se(coef)      z Pr(>|z|)    \nage                  0.05647   1.05810  0.01457  3.875 0.000107 ***\nprioryes            -0.70778   0.49274  0.44368 -1.595 0.110655    \ntransplanttreatment -1.72587   0.17802  0.28398 -6.077 1.22e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                    exp(coef) exp(-coef) lower .95 upper .95\nage                    1.0581     0.9451    1.0283    1.0888\nprioryes               0.4927     2.0295    0.2065    1.1756\ntransplanttreatment    0.1780     5.6174    0.1020    0.3106\n\nConcordance= 0.746  (se = 0.031 )\nLikelihood ratio test= 47.31  on 3 df,   p=3e-10\nWald test            = 48.37  on 3 df,   p=2e-10\nScore (logrank) test = 55.28  on 3 df,   p=6e-12\n\n#compare model that includes acceptedyear and that does not\n#high p value, there is not a statistically significant difference between the two models, can\n#drop the variable\nanova(all.mod, all2.mod, test=\"LRT\")\n\nAnalysis of Deviance Table\n Cox model: response is  Surv(survtime, survived2)\n Model 1: ~ acceptyear + age + prior + transplant\n Model 2: ~ age + prior + transplant\n   loglik  Chisq Df Pr(>|Chi|)\n1 -255.49                     \n2 -256.28 1.5784  1      0.209\n\n\nThe C-statistic for the model without an accepted year is equal to 0.739 (see Table 3). Which shows that this model has a higher predictability capabilities compared to the model including the accepted year with a C-statistic = 0.683."
  }
]